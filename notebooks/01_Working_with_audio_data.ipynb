{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "authorship_tag": "ABX9TyMqNmz9PJAZGc9ZZAImSkkC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10udCryp7/Speech-Practice/blob/main/notebooks/01_Working_with_audio_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD3QweSKg1Pf"
      },
      "outputs": [],
      "source": [
        "# pip install -U datasets\n",
        "!pip install -U datasets[audio]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "0sIfj-4W38Mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('hf-internal-testing/librispeech_asr_dummy', split = 'validation')"
      ],
      "metadata": {
        "id": "dkXbtZIUxfiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Waveform"
      ],
      "metadata": {
        "id": "117itmoY3_RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get array of waveform\n",
        "sample_array = dataset[0]['audio']['array']\n",
        "print(f'array: {sample_array}')\n",
        "\n",
        "# get tensor of waveform\n",
        "sample_tensor = dataset[0]['audio'].get_all_samples().data\n",
        "print(f'tensor: {sample_tensor}')"
      ],
      "metadata": {
        "id": "CY4xijGwzkqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  audio = dataset[0]['audio']['sampling_rate'], sample_array\n",
        "  output = gr.Audio(audio, 'test')\n",
        "\n",
        "demo.launch(debug = True)\n"
      ],
      "metadata": {
        "id": "kUIQHwHE2N2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize Waveform"
      ],
      "metadata": {
        "id": "CEl-Rwp04FOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "array = sample_array\n",
        "sr = dataset[0]['audio']['sampling_rate']\n",
        "\n",
        "plt.figure(12)\n",
        "librosa.display.waveshow(array, sr=sr)"
      ],
      "metadata": {
        "id": "x59kumPV4Jhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resampling with cast_column"
      ],
      "metadata": {
        "id": "oXsselLt4_vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Audio\n",
        "\n",
        "dataset_32k = dataset.cast_column('audio', Audio(sampling_rate = 32000))\n",
        "\n",
        "dataset_32k.features['audio']"
      ],
      "metadata": {
        "id": "kq69VDqE5E0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter"
      ],
      "metadata": {
        "id": "zZfnPMsu96o8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd .."
      ],
      "metadata": {
        "id": "zAMYW3x4_ZlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_DUR = 10.0"
      ],
      "metadata": {
        "id": "PEfsahzfA4_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_length(audio_dur):\n",
        "  return audio_dur < MAX_DUR\n",
        "\n",
        "dur_col = [librosa.get_duration(y = audio['array'], sr = audio['sampling_rate']) for audio in dataset['audio']]\n",
        "\n",
        "dataset = dataset.add_column(\"duration\" , dur_col)"
      ],
      "metadata": {
        "id": "5a3JWY3R5Snt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.filter(filter_length, input_columns=['duration'])"
      ],
      "metadata": {
        "id": "WaXGWMGX-6P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.remove_columns(['duration'])"
      ],
      "metadata": {
        "id": "a1ClHUo8-7hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Extractor"
      ],
      "metadata": {
        "id": "UDQj8AMSBf1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")"
      ],
      "metadata": {
        "id": "agqs0OmfBhTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor(sample_array, sampling_rate = 16000, padding = True)"
      ],
      "metadata": {
        "id": "2hMF26GvDnAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_data(sample):\n",
        "  audio = sample['audio']\n",
        "  features = feature_extractor(audio['array'], sampling_rate = audio['sampling_rate'], padding = True)\n",
        "\n",
        "  return features"
      ],
      "metadata": {
        "id": "M4zUzfSGCvmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(prep_data)"
      ],
      "metadata": {
        "id": "U-N96R3uDJuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "example = dataset[0]\n",
        "\n",
        "librosa.display.specshow(np.asarray(example['input_features'][0]),\n",
        "                         sr = feature_extractor.sampling_rate,\n",
        "                         hop_length = feature_extractor.hop_length,\n",
        "                         x_axis = 'time',\n",
        "                         y_axis = 'mel')\n",
        "\n",
        "\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "T__aGNrwEP09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AutoProcessor"
      ],
      "metadata": {
        "id": "AlzVAUipFJxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"openai/whisper-small\")"
      ],
      "metadata": {
        "id": "4taCiNyMFL4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming"
      ],
      "metadata": {
        "id": "hpTEWY5d2laL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets[audio]"
      ],
      "metadata": {
        "id": "XFLhb9WD5ATx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('hf-internal-testing/librispeech_asr_dummy', split = 'validation', streaming = True)"
      ],
      "metadata": {
        "id": "EFbHEQDY2nF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(iter(dataset)))"
      ],
      "metadata": {
        "id": "yA9f7lab272d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}